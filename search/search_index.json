{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Introduction","text":"<p>Physical Network Theory</p> <p>These notes on data communications are a basic introduction and are intended to let us share a basis of terminology and understanding. Many of the topics I will cover require a rigorous, theoretical treatment to understand properly. That is not what is intended here!</p> <p>Much of the magic of modern technology emerges because we can communicate between devices and thus between people. Even the most far-fetched sci-fi of the 1960s did not include the iPhone or ubiquitous connectivity and the changes since the pandemic have established communication technology as being one of the key enablers of modern civilization.</p> <p>There are key terms. These will be italicized. You may need to look up these terms to get a full understanding of them.</p> <p>Commands are generally shown in bold.</p>"},{"location":"1.%20Fundamentals/1/","title":"Digital Signals","text":"<p>We tend to have two distinct types of signal which we deal with. The word analogue means that we are representing a value which continuously varies. For example, the fuel gauge in a car can indicate from full to empty and can indicate any value in between. An analogue signal has a theoretically infinite resolution.</p> <p>Digital systems have distinct values like \u201c1\u201d or \u201c0\u201d. If I have a digital fuel gauge, it typically shows 10 steps from full to empty. In circuits, we tend to deal with logic levels where for example +5V is a one and 0V is a zero.</p> <p>A computer is primarily made up of digital components and circuits which tend to have very defined signal levels to represent ones and zeros.</p> <p>A guitar amplifier is (probably!) entirely made of analogue circuits; typically, a pre-amplifier and a power amplifier. And the really fun ones still use thermionic valves (look it up).</p> <p>A telephone exchange will have both types of circuit, analogue electronics to process incoming and outgoing voice signals to the user and digital circuits to transmit voice between exchanges.</p> <p>A signal with a one or zero level is binary, the signal will be above a threshold value for 1 and below a threshold value for 0.</p> Fig 1. A binary signal. <p>There is another alternative where we can send multiple voltage levels and where one symbol can be transmitted per voltage level. For example, suppose we make  - 0V equal to 00 - 1V equal to 01 - 2V equal 10 - 3V equal to 11. </p> <p>When we have transmitted two bits of information for each symbol we transmit; this is very efficient. We refer to a multi-level system like this as an m-ary system, where m is the number of levels.</p> Fig 2. A m-ary signal."},{"location":"1.%20Fundamentals/2/","title":"Asynchronous Serial Communications","text":"<p>One of the oldest and simplest ways we can communicate is via serial links. Ones and zeros are represented as voltage levels and each bit follows the other down a wire. Imagine we had a keyboard connected via a serial link to a computer. We would be sending one character at a time, the user could press a key at any random time, so characters could come down the wire at any time. This is called an asynchronous link. We need a way to distinguish the start of a character; this is called the start bit and will always be a 1 (because if it was a 0, we could not distinguish it from a line with no activity). After this, we could transmit our character. In early systems, we did this using 7 bits. We need to be able to show that we have finished sending the character. This is because there is no timing information between the two sides of a link. The only way we can synchronize the two sides is to know where a character starts and stops. Normally we use two stop bits.</p> Fig 3. A byte with framing. <p>In the example shown, we have a single character being sent, with the binary code 0110010. We mentioned timing above. Our serial links can have a range of speeds; the standard bit rate speeds are 300, 1200, 2400, 4800, 9600, 14400, 19200, 28800, 38400, 57600, 115200, 230400. I have seen a 400kb/s speed quoted.</p> <p>There are many examples of standard protocols which use serial links. The most common is RS-232. This is an old standard now and most laptops no longer have it. Every technical person has an adapter in their laptop case which allows them to use RS-232 over USB and you can buy an adapter like that on line for a few euros. If you don\u2019t have one ORDER ONE NOW! You cannot configure network equipment of appliances without it. When you connect to a Cisco switch or router via a blue serial cable, this is RS-232.</p> <p>If you are doing longer range serial connections, you might use a standard like RS-422 or RS-485. For very long connections in industrial sites, we use a 4-20mA current loop. For IoT sensors, I use 1-wire devices, a specific proprietary protocol that is both simple and cheap.</p>"},{"location":"1.%20Fundamentals/3/","title":"Synchronous Communications","text":"<p>In some cases, we need something more precise than asynchronous communications. It may be desirable for us to synchronize the two sides of a communication circuit by including a clock signal on a separate line.</p> Fig 4. Serial with clock. <p>Using synchronous circuits, we can connect at multi-megabit rates. When you use legacy thick Cisco serial cables to connect to serial WAN ports on a router, this is a synchronous connection.</p>"},{"location":"1.%20Fundamentals/4/","title":"Bits, Nibbles, Bytes and Words","text":"<p>It would be unusual for us to want to exchange single bits. We could exchange data in groups of 4 bits, this is called a nibble and is very unusual. However, the first production microprocessor (4004) was a 4-bit computer.</p> <p>When we began exchanging characters first, we did so with a standard called ASCII, the American Standard Code for Information Interchange. Work began on this in 1960 with the American Standards Association's (ASA) X3.2 subcommittee and the standards were released in 1963, revised in 1967 and 1986. ASCII was developed from early telegraphic codes, and its first commercial use was as a 7-bit teleprinter code. 7 bits gives us 2<sup>7</sup> or 128 possible characters.</p> <ul> <li>26 Capital (65-90) and 26 Lower Case (97-122)</li> <li>10 Numbers (48-57)</li> <li>32+1 Control Characters (0-31, 127)</li> </ul> <p>It may seem strange to use 7 bits, but we needed some other things like start and stop bits and our early serial chips could only cope with 10 bits. Eventually extended ASCII was developed and includes definitions for 2<sup>8</sup> or 256 characters. The generation of microprocessors from the 8008 onward used 8 bits internally, a byte. </p> <p>Some early mainframes and mini computers used 12 bits!</p> <p>As symbol lengths went above 8 bits, we used the term word. We can have 16, 32, 64 bit words.</p>"},{"location":"1.%20Fundamentals/5/","title":"Unicode","text":"<p>ASCII was very limited with no support for languages, symbols etc. Unicode was a solution developed in the late 1980s and standardized in 1991. Unicode standardized numeric representations for symbols required for international writing. Unicode is backward compatible with ASCII (UTF-8). A Unicode character is represented by the format U+ followed by the character code in HEX. For example, U+0041 is the ASCII character A. The most recent specification for UNICODE is Unicode v.6.</p> <p>ASCII has now been superseded by UNICODE. Do some background reading on ASCII and UNICODE and ensure you understand it.</p>"},{"location":"1.%20Fundamentals/6/","title":"Errors and Parity","text":"<p>Communications links can be affected by electrical noise and now and then, a spike of noise can cause a bit error in a circuit.</p> Fig 5. Noise. <p>The noise voltage will be superimposed on the signal, the receiver will be unable to distinguish between a symbol caused by noise and the original intended signal.</p> <p>To counteract the effect of noise causing a bit error, we use parity. We add up all the bits in the original signal. There were four 1\u2019s and that is an even number, so we could make our parity value 0. If we added them up and they made an odd number, we could make our parity value 1. We can then add a parity bit to the end of our data, before the stop bit.</p> <p>Parity will allow us to find any single bit error in a character. It will not allow us to detect two or more bits of error (why?).</p>"},{"location":"1.%20Fundamentals/7/","title":"Parallel Links","text":"<p>Another strategy for data communications is to pass a byte (8 bits) or a word (16 or 32 bits) at a time. Imagine two computers have a connection with eight data lines, D0-D7. Now I can transmit a byte at a time. If the link speed is the same as serial, I now have eight-times the data transfer rate. This would seem to be a far better solution than serial.</p> <p>Unfortunately, once our links are very fast, we start running into problems. Every one of the eight links must have the same signal transfer characteristics, or we end up with bits arriving out of alignment.</p> <p>Most modern systems use multiple serial links instead of parallel links.</p> Fig 6. Parallel Links."},{"location":"2.%20Signals/1/","title":"Sine Waves","text":"<p>Consider a rotating machine like a wheel. If I divide the rotor into eight segments (45\u00b0 each) and then plot the X axis in eight parts, I can get an idea of the path a point on that wheel will follow as it rolls.</p> <p>This is a sine wave, and they appear in many aspects of nature. They are critical to our understanding of communications.</p> <p>Its blocky and unnatural looking in my diagram (quick and nasty, generated in Excel), If I divided my circle into 16 or 32, it would look better!</p> Fig 7. Sine Waves. <p>From one ascending value to another is the wavelength (\u03bb).</p> <p>The frequency (f) is how many full cycles per second occur. I divided my wave into 8 segments, 360/8 = 45\u00b0 and the time taken for that part of the wave to pass will be 1/8f.</p> <p>The amplitude is the size of the wave, if this was an electrical wave, it might be the peak voltage.</p>"},{"location":"2.%20Signals/2/","title":"Sound Waves","text":"<p>The communications medium we first experience is sound. When we experience sound, our ears interpret the varying pressure of compressions waves as they travel through the air. When you hear a perfect, pure tone (for example a tuning fork) this is a sine wave. These waves occur naturally in range of different circumstances, for example, ocean waves, light, the bell tone of a guitar string.</p> <p>The lowest sounds we normally hear are the hum which is associated with electrical equipment plugged into the mains electricity. This is caused by the mains voltage varying at around fifty times per second. Variations or cycles per second are given the unit of hertz (Hz) and are a measurement of frequency, so 50 cycles per second is referred to as 50 Hz. Most people can hear sounds even lower than this, perhaps down to 20 Hz. Frequency is normally designated by the letter f.</p> <p>The speed of sound in air at sea-level is about 300ms<sup>-1</sup> (V).</p> <p>If a sound wave of 50 Hz passed you by at 300ms<sup>-1</sup> then the distance between the peak of each wave would be 300/50 = 6m. This would be the wavelength which is normally designated by the Greek letter lambda (\u03bb).</p> <p>To convert between wavelength and frequency, we need to know the speed the sound wave is travelling at.</p> <p>Wavelength=(Velocity of Wave)/Frequency or \u03bb=V/F</p> <p>A sound signal can be loud or quiet. We use the term amplitude to describe how \u201cbig\u201d the signal is. The highest frequency you can hear depends on your age, but a young person may hear sounds up to 20 kHz or twenty thousand hertz.</p> <p>As you get older, your ability to hear high frequencies diminishes and thrash metal bands just don\u2019t sound the same anymore.</p>"},{"location":"2.%20Signals/3/","title":"Noise","text":"<p>Along with any signal, we are always going to have noise. We use the term noise colloquially, the background hum that can make conversation difficult. In systems terms, noise is an irregular fluctuation, typically accompanying any electrical signal. The relationship between the noise level and the signal level is referred to as the signal/noise (S/N) ratio.</p> <p>As atoms heat up, the random motions of electrons increase, this is the fundamental cause of electrical noise. Noise and temperature are closely associated. To make quantum computers operate, I need a cryogenic plant and temperatures very close to absolute zero.</p> <p>Noise is incredibly important from a theoretical perspective and determines many of the characteristics of a telecommunications channel.</p>"},{"location":"2.%20Signals/4/","title":"Model - Generating a Sine Wave","text":"<p>Give this a go!</p> <p>In Excel, Column A, I create a list of numbers from 0 to 430.</p> <p>In column B, I insert the formula </p> <p>SIN(RADIANS(A1))</p> <p>and apply it to the entire range.</p> <p>I have created a SINE wave of amplitude 1. The wavelength (\u03bb) is measured from zero crossing to zero crossing. The amplitude (A) is measured from zero to the peak of the wave.</p> <p>I could also measure the peak-to-peak amplitude which would be 2A.</p> Fig 8. Generate a sine Wave."},{"location":"2.%20Signals/5/","title":"Angular Frequency","text":"<p>There are many ways we can measure angles, but radians are one of the most useful. If you trace the length of the radius around a circle, it will cover around 57\u00b0 and this is one radian.</p> <p>The circumference of a circle is 2\u03c0 radians (think about it!).</p> <p>Consider a rotating machine like a wheel. If it rotates once per second, it has an angular rotation frequency (\u03c9) of 2\u03c0 radians per second. The units will always be rads/second.</p>"},{"location":"2.%20Signals/6/","title":"Waveforms","text":"<p>Blues, heavy metal, and rock tend to have a distorted guitar sound. For Rory Gallagher\u2019s kind of blues, one of the stages of the amplifier is overdriven, causing the sine waves to be squared off a little on top. If this is beyond your musical expertise, have a listen on the Internet. This also has the effect of adding some sustain to the sound by compression.</p> <p>Some of Santana\u2019s music is much more distorted and has massive sustain. Technically this is called distortion, the effect is created by turning the nice pure sine waves which a guitar\u2019s pickups produce, into square waves.</p> <p>There are other kinds of waves we find in use in technology, including triangular waves and saw-tooth waves. We mostly experience these as electrical signals with waves in voltage, current, power.</p> <p>We may display these signals with voltage on the vertical axis (Y) and time on the horizontal axis (X). As time is used for one axis, we refer to this as a display in the time domain.</p> Fig 9. Signals in the time domain. <p>When a signal is viewed using a device called an oscilloscope, it appears as a continuous varying waveform. I can use a signal generator (pictured on the right) to create and view test signals on the oscilloscope (pictured on the left).</p> Fig 10. Oscilloscope and Function Generator. <p>Some complex signals do not appear to have a pattern, one way to model these waveforms is to see them as being made up from many sine waves of different frequencies and different amplitudes. The mathematics behind this is called Fourier Analysis and it is the basis for much of electronic design and modelling.</p> <p>Do a little background reading on Fourier Analysis now.</p> <p>There is a second instrument we use to look at signals, called a spectrum analyzer. This looks at signals with the horizontal axis showing frequency. We refer to a diagram like this as being in the frequency domain.</p> Fig 11. Signals in the frequency domain. <p>Imagine we have an audio signal from a phone, 3.1 KHz bandwidth, modulated onto a carrier of 100 KHz. If we were to view the signal in the time domain, we would see energy in frequencies from 97-103 KHz.</p> <p>The areas on either side of the carrier are called sidebands. The actual carrier itself provides no information and can be suppressed before the signal is amplified and transmitted.</p>"},{"location":"2.%20Signals/7/","title":"Bandwidth","text":"<p>We have seen that a full audio signal (to your ears!) will be perceived from 20 Hz to 20,000 Hz. We can refer to this as the bandwidth. Sometimes we reduce the bandwidth to make signalling easier or economical.</p> <p>For example, a landline telephone probably allows signals from 300 Hz to 3.4 kHz with a bandwidth of 3.1 kHz, that is why it sounds a bit tinny. Long Wave or Medium Wave Radio has a bandwidth of 5 or 10 kHz, sounding almost as bad. VHF radio uses a bandwidth of 200 kHz and that sounds almost as good as a CD.</p>"},{"location":"2.%20Signals/8/","title":"Harmonics","text":"<p>Sometimes we use the term harmonics to describe frequencies that \u201csound good\u201d with other frequencies. This works because the frequencies have a mathematical relationship to each other. On a piano, middle C has a frequency of 261.626 Hz. The next C above middle C has a frequency of c. 523 Hz....double!</p> <p>To make a major chord, the frequencies have a ratio of 4:5:6. For example a major chord from middle C would have a next note at (261.626/4) * 5 = 327 Hz or the key of E.</p> <p>In signals, if the first or fundamental frequency (first harmonic) is X Hz, the frequencies of the next harmonics are: </p> <ul> <li>2* fundamental frequency Hz (2nd harmonic)</li> <li>3* fundamental frequency Hz (3rd harmonic)</li> <li>4* fundamental frequency Hz (4th harmonic)</li> </ul> <p>The waves sound good to us because the peaks and troughs tend to line up. We call waves which behave like that in phase.</p>"},{"location":"2.%20Signals/9/","title":"Phase","text":"<p>Phase is a very important concept to us. We say that a wave goes from one peak to another in 360\u00b0 (like a circle). A wave that starts 30\u00b0 after an initial wave is said to be 30\u00b0 out of phase.</p> <p>I created some extra columns in my Excel sheet, the graph below shows 3 SIN waves, 30\u00b0 out of phase and 60\u00b0 out of phase.</p> Fig 12. Sine waves spaced 30\u00b0."},{"location":"2.%20Signals/A/","title":"Information Theory","text":"<p>Claude Shannon was arguably one of the most significant engineers in the field of digital circuit design. However, he is more remembered for his contributions to information theory from 1948 [1]. Shannon wanted to know how much information could be passed across a channel, in theory. Shannon stated that \u201cThe fundamental problem of communication is that of reproducing a message sent from one point, either exactly or approximately, to another point\u201d In Shannon\u2019s models we have:</p> <ol> <li>An information source or Sender that produces a message</li> <li>A Transmitter (TX) which creates encodes a signal to be sent through a channel</li> <li>Information that composes the message</li> <li>A Channel, the medium over which the signal is transmitted</li> <li>Noise, background noises in the channel for an audio signal, electrical noise in the channel for an electrical signal.</li> <li>A Receiver (RX), which decodes the signal back into the message, a destination, for which the message is intended.</li> </ol> <p>Changing the characteristics of any of the terms above determines how much information can pass through a channel. Everything in the universe can be described in terms of bits, information theory was ground-breaking for a range of areas in physics.</p> <p>Although not the originator of the term, Shannon also defined the bit as a unit of information. Flip a fair coin, you have a single bit of information (heads/tails). Consider an unfair coin that will land only on heads, each flip provides zero information. If an unfair coin lands on heads 2/3 of the time, the information in each flip is 0.92 bits.</p> <p>If you have dice at home, there are 2.7 bits of information per throw (on average, how many guesses you would have to make to figure out what number I threw). In information theory, you can have fractions of bits! The more you know about something, the less random it seems and therefore the less information per result. True randomness has the highest possible information content.</p> <p>Shannon defined information entropy to measure the information content in a message, and the measure of uncertainty in the message. All this applies widely, for example to natural language.</p> <p>If you compress a file of predictable information (all white) it will be tiny. If you compress a file of truly random data (white noise), the compressed file will be about the same size as the uncompressed file.</p> <p>As an example, consider the two lines below.</p> <ul> <li>[AB, AB, AB, AB, AB, AB, AB, AB, AB, AB, AB, AB, AB, AB, AB, AB]</li> <li>[AB] * 16</li> </ul> <p>They both contain the same information; one can be communicated much more efficiently that the other. The first will compress well, the second will not. If you are interested in this, do some background reading on LZW compression [2]. \u2003</p> <p>[1] Shannon, C.E., 2001. A mathematical theory of communication. ACM SIGMOBILE mobile computing and communications review, 5(1), pp.3-55.</p> <p>[2] Welch, T.A., 1984. A technique for high-performance data compression. Computer, 17(06), pp.8-19.</p>"},{"location":"3.%20Modulation/1/","title":"Definition","text":"<p>A voice signal on an old fashioned telephone has most of its energy between 300Hz and 3.4KHz. Let us design a radio antenna to transmit 300Hz!</p> <p>We know that the wavelength (\u03bb) = c/f</p> <p>If </p> <ul> <li>c = 3 x 10 <sup>8</sup> m/s</li> <li>f = 300Hz</li> </ul> <p>Then a full wavelength antenna would be \u03bb = 3 x 10<sup>8</sup> / 300 = 1,000 kms long!</p> <p>There are (a great number of!!) other reasons why it would be impractical to build a radio transmitter and receiver at these frequencies. We might prefer to pick radio frequencies for their propogation characteristics, equpment design, etc. This will be the carrier.</p> <p>We can then change a property of this signal to transmit information, this is modulation. </p> <p>For the diagrams (AM, FM, PM) on the following pages, I did some very rough Python scripts (based on some scripts I generated from ChatGPT). Take a look at the code and see if you can run it. If you are not familiar with virtual envirnments, read prereqs.py and install the prerequisites before you begin.</p>"},{"location":"3.%20Modulation/2/","title":"Amplitude Modulation (AM)","text":"<p>Amplitude Modulation is where the amplitude (or loudness) of the sound is used to modulate a carrier. A typical way to use AM is experienced when we listen to medium wave or long wave radio (called AM on many radio sets).</p> Fig 13. AM Waves. <p>We start with a radio wave; in the case of RTE Longwave the carrier wave is 252 kHz or 252,000 Hz.</p> <p>Suppose we modulate the amplitude of the carrier using an audible signal, the note middle C on a piano (261 Hz). We can transmit a radio wave which varies in amplitude with the audio signal. This can be transmitted for hundreds of miles, with the audio signal recoverable by a radio receiver.</p> <p>Amplitude modulation is simple and cheap to implement. However, it is impossible to distinguish noise from signal, and when the carrier becomes weak (called fading), so does the recovered audio.</p>"},{"location":"3.%20Modulation/3/","title":"Frequency Modulation (FM)","text":"<p>Frequency Modulation (FM) is a bit more useful for us music lovers!</p> <p>In this case, we change the frequency of the carrier in response to the modulating signal. This kind of modulation is much more immune to noise. However, instead of using a single frequency, FM uses a band of frequencies around the carrier. How much frequency spectrum is used is referred to as bandwidth.</p> Fig 14. FM Waves. <p>Consider a carrier with a frequency of Fc modulated by a signal with a frequency of F0</p> <p>Where the signal F0 is positive, the frequency is added to the carrier Fc. Where it is negative, it is subtracted.</p> <p>The resultant waveform varies in frequency from F0 + Fc to F0 - Fc</p>"},{"location":"3.%20Modulation/4/","title":"Phase Modulation (PM)","text":"<p>Phase Modulation (PM) is a far more complex technique requiring sophisticated electronics. With PM, we encode information in the phase of a wave. This requires a high-quality communications channel with a minimum of noise. We use a special version of PM for sending digital signals, Phase Shift Keying or PSK.</p> <p>In simple terms, we take a carrier signal and then figure out how good our communication channel is. Suppose our channel is so good, we can distinguish between eight phase changes in our wave or a phase shift of 45 degrees.</p> <p>Now we can make zero phase shift equal to binary 000, we can make a 45-degree phase shift equal to binary 001 and so on. We have made each or the 8 possible phase shifts equal to a 3-bit binary symbol. This is great! It means we can transmit 3 bits of data for every single phase of the carrier. Again, in very simple terms, it means we can get 3,000 bits per second from a carrier at only 1 kHz.</p> Table 1. Encoding in phase shifts. Fig 15. Phase Modulation."},{"location":"3.%20Modulation/5/","title":"Quadrature Amplitude Modulation (QAM)","text":"<p>The most complex modulation we will consider is a combination of some of these techniques called Quadrature Amplitude Modulation (QAM).</p> <p>Waves are combined with differing phases and amplitudes to create a complex resultant wave. If the channel quality is good, a high number of bits can be communicated per cycle. For example, QAM16 has 16 symbols/4 bits, QAM64 has 64 symbols/8 bits.</p> <p>Typical wireless broadband services use 64QAM.</p> <p>Power line Ethernet uses up to 4,096QAM and the (current!) most advanced DSL technology uses 32,768QAM.</p> <p>For QAM, take a look at this repo and run QAM_Explanation/qam_updated_multigraph_animation_2.py</p> <p>If you installed the prereqs as I mentioned in the definition section, this should run out-of-the-box.</p> <p>This is much better than any quick code I could write. Watch the associated YouTube video</p>"}]}